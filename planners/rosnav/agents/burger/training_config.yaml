agent_name: burger_AGENT_66_2024_03_22__16_04_07
callbacks:
  periodic_eval:
    eval_freq: 8000
    max_num_moves_per_eps: 800
    n_eval_episodes: 40
  stop_training:
    threshold: 0.92
    threshold_type: succ
  training_curriculum:
    curr_stage: 1
    lower_threshold: 0.6
    threshold_type: succ
    training_curriculum_file: default.yaml
    upper_threshold: 0.85
debug_mode: false
goal_radius: 0.25
max_num_moves_per_eps: 600
monitoring:
  cmd_line_logging:
    episode_statistics:
      enabled: true
      last_n_eps: 25
    training_metrics:
      enabled: true
  eval_log: true
  use_wandb: true
n_envs: 10
n_timesteps: 40000000
no_gpu: false
rl_agent:
  action_space:
    custom_discretization:
      buckets_angular_vel: 11
      buckets_linear_vel: 8
      enabled: true
    discrete: false
  architecture_name: AGENT_66
  checkpoint: best_model
  frame_stacking:
    enabled: true
    stack_size: 3
  laser:
    full_range_laser: false
    reduce_num_beams:
      enabled: false
      num_beams: 200
  lr_schedule:
    enabled: true
    settings:
      final_value: 0.0001
      initial_value: 0.001
    type: linear
  normalize:
    enabled: true
    settings:
      clip_obs: 30.0
      clip_reward: 20.0
      gamma: 0.99
      norm_obs: true
      norm_reward: false
  ppo:
    batch_size: 20480
    clip_range: 0.25
    ent_coef: 0.005
    gae_lambda: 0.95
    gamma: 0.99
    learning_rate: 0.0003
    m_batch_size: 512
    max_grad_norm: 0.5
    n_epochs: 3
    n_steps: 2048
    vf_coef: 0.22
  resume: burger_AGENT_66_2024_03_22__16_04_07
  reward_fnc: convex_e2e
  space_encoder: RobotSpecificEncoder
robot: burger
safety_distance: 0.4
tm_modules: staged
tm_obstacles: random
tm_robots: random
