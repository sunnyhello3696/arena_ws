mpc:
   T: 0.2 # [s]
   N: 10 # Receding horizon (steps), N > 20 seems to require too much CPU power
   k: 1 # b-spline order
   if_add_robot_pt: false # Add robot position at the first point of the action points
   feasible_position_speed_factor: 1.0 # Factor to calculate the feasible position speed
   if_promote_goal_in_convex: true
   angle_or_last_pt: true # If the goal is in the convex, if true, the the action points angle set to goal angle; if false, set goal to the last action point
   last_pt_include_reward_cal: true # Set goal as the last action point when calculating reward
   xmin1: [-10, -10, -10] # Min ERROR from reference trajectory ([m], [m], [rad])
   xmax1: [10, 10, 10]  # max ERROR from reference trjectory ([m], [m], [rad])
   umin1: [-0.8, -2.24]  # Min absolute control input ([m/s], [rad/s])
   umax1: [0.8, 2.24]  # Max absolute control input ([m/s], [rad/s])
   Q1:
      - [300, 0, 0]
      - [0, 300, 0]
      - [0, 0, 400]
   QN1:
      - [300, 0, 0]
      - [0, 300, 0]
      - [0, 0, 400]
   R1:
      - [300, 0]
      - [0, 400]
   # T: 0.2 # [s]
   # N: 10 # Receding horizon (steps), N > 20 seems to require too much CPU power
   # xmin1: [-0.4, -0.5, -0.45] # Min ERROR from reference trajectory ([m], [m], [rad])
   # xmax1: [0.4, 0.5, 0.45]  # max ERROR from reference trjectory ([m], [m], [rad])
   # umin1: [-0.7, -2.23]  # Min absolute control input ([m/s], [rad/s])
   # umax1: [0.7, 2.23]  # Max absolute control input ([m/s], [rad/s])
   # Q1:
   #    - [200, 0, 0]
   #    - [0, 200, 0]
   #    - [0, 0, 100]
   # QN1:
   #    - [200, 0, 0]
   #    - [0, 200, 0]
   #    - [0, 0, 100]
   # R1:
   #    - [50, 0]
   #    - [0, 50]
